<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Map&Make: Schema Guided Text to Table Generation">
  <meta name="keywords" content="">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Map&Make: Schema Guided Text to Table Generation</title>

  <!-- Global site tag (gtag.js) - Google Analytics
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script> -->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.svg"> -->
  <link rel="icon" href="./static/images/coral-logo.jpeg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Map&Make: Schema Guided Text to Table Generation</h1>
          <div class="is-size-4 publication-authors">
            <span class="author-block">
              <a href="https://mcharold404.github.io/">Naman Ahuja</a><sup>1*</sup>,</span>
            <span class="author-block">
              <a href="https://fenil-b.github.io">Fenil Bardoliya</a><sup>1*</sup>,</span>
            <span class="author-block">
              <a href="https://chitta.orissalinks.com/www/">Chitta Baral</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://vgupta123.github.io/">Vivek Gupta</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-4 publication-authors">
            <span class="author-block"><sup>1</sup>Arizona State University</span>
            <span class="eql-cntrb"><small><br><sup>*</sup>Equal contribution</small></span>
          </div>

          <br><center><h2 class="title is-3" style="color: red;">ACL 2025 (Main)</h2></center>

          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="https://arxiv.org/abs/2505.23174"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://drive.google.com/file/d/16sZNx_Ll0hk0nNpHd-KVriozSde8BvBE/view?usp=drivesdk"
                   class="external-link button is-normal is-rounded is-dark"
                   target="_blank" rel="noopener">
                  <span class="icon">
                      <i class="fas fa-video"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Presentation Link. -->
              <span class="link-block">
                <a href="https://drive.google.com/file/d/1lunNBjeLNCwK7Ss4FGaFDLr86OiaQyCt/view?usp=sharing"
                   class="external-link button is-normal is-rounded is-dark"
                   target="_blank" rel="noopener">
                  <span class="icon">
                      <i class="fas fa-file-powerpoint"></i>
                  </span>
                  <span>Slides</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/coral-lab-asu/map-make/tree/main/code"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://huggingface.co/datasets/McH04/Rotowire-Text-to-Table"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-database"></i>
                  </span>
                  <span>Dataset</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Transforming dense, unstructured text into interpretable tables is essential for information extraction. We introduce <strong>Map&Make</strong>, a prompting pipeline that scales test-time compute to improve information coverage and integration across diverse text-to-table tasks. Our approach decomposes text into atomic propositions, extracts latent schemas, and generates tables capturing both qualitative nuances and quantitative facts. We evaluate on three challenging datasets: <strong>RotoWire</strong> (complex multi-table schema), <strong>Livesum</strong> (numerical aggregation), and <strong>Wiki40B</strong> (open-domain extraction). By correcting hallucination errors in RotoWire, we provide a cleaner benchmark. Map&Make demonstrates significant gains across comprehensive metrics and enables effective supervision for fine-tuning smaller models.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Introduction -->
<section class="section" style="padding-top: 1rem;">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Introduction</h2>
        <div class="content has-text-justified">
          <p>
            Text-to-table generation requires extracting structured information from unstructured narratives—a task that challenges current LLMs in determining <em>what</em> to extract and <em>how</em> to infer missing information. Map&Make addresses these challenges through a modular pipeline that scales test-time computation: atomizing text into propositions, extracting schemas, and generating tables. This approach improves performance across datasets with different characteristics—from sports summaries requiring complex schemas to live data demanding numerical reasoning to open-domain content needing flexible extraction.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Datasets -->
<section class="section" style="padding-top: 1rem;">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Datasets</h2>
        <div class="content has-text-justified">
          <p>
            We evaluate on three diverse benchmarks: <strong>RotoWire</strong> (728 NBA game summaries requiring multi-table schemas), <strong>Livesum</strong> (1,462 Chinese social media posts with numerical aggregation), and <strong>Wiki40B</strong> (100 open-domain articles spanning diverse topics). For RotoWire, we provide a corrected test set addressing hallucination errors in the original annotations (available on <a href="https://huggingface.co/datasets/McH04/Rotowire-Text-to-Table">Hugging Face</a>). These datasets collectively stress-test schema flexibility, numerical reasoning, and information coverage.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Evaluation Metrics -->
<section class="section" style="padding-top: 1rem;">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Evaluation</h2>
        <div class="content has-text-justified">
          <p>
            We employ both <strong>comparative metrics</strong> (Exact Match, chrF, BERTScore) for cell-level accuracy and <strong>referenceless metrics</strong> to assess table quality without gold references. <strong>TabEval</strong> uses entailment models to verify table-text consistency, while <strong>AutoQA</strong> measures question-answering fidelity. For numerical tasks, we report error rates and RMSE to capture aggregation accuracy. This comprehensive evaluation suite enables robust assessment across different dataset characteristics.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section" style="padding-top: 1rem;">
  <div class="container is-max-desktop">
    <!-- Key Idea: Framework -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Key Idea: Map&Make Pipeline</h2>
        <div class="content has-text-justified">
          <p>
            Map&Make is a modular 3-step prompting pipeline that scales test-time compute: <strong>(1) Atomization</strong> decomposes text into atomic propositions, <strong>(2) Schema Extraction</strong> identifies latent table structures, and <strong>(3) Table Generation</strong> populates cells using extracted information. This decomposition enables better information coverage and integration compared to end-to-end approaches, allowing the model to reason step-by-step about what to extract and how to structure it.
          </p>
          <br>
          <img src="./static/images/M&M.jpg" alt="Map&Make Framework"/>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Results Section -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h1 class="title is-2">Results</h1>
        
        <!-- RotoWire: Comparative Metrics -->
        <h2 class="title is-3">RotoWire: Comparative Metrics</h2>
        <div class="content has-text-justified">
          <p>
            Map&Make outperforms Chain-of-Thought and T3 baselines across cell-level metrics (Exact Match, chrF, BERTScore) on both GPT-4o and Gemini-2.0. The modular pipeline's step-by-step reasoning improves extraction accuracy, particularly for complex multi-table schemas with player and team statistics.
          </p>
        </div>
        <img src="./static/images/table2.png" width="600"/>
        <br><br>

        <!-- RotoWire: Referenceless Metrics -->
        <h2 class="title is-3">RotoWire: Referenceless Metrics</h2>
        <div class="content has-text-justified">
          <p>
            Using TabEval (entailment-based evaluation) and AutoQA (question-answering fidelity), Map&Make demonstrates superior table-text consistency and information coverage. These referenceless metrics confirm that our pipeline generates tables more faithful to the source text, beyond just matching gold annotations.
          </p>
        </div>
        <img src="./static/images/table3.png" width="600"/>
        <br><br>

        <!-- Livesum -->
        <h2 class="title is-3">Livesum: Numerical Aggregation</h2>
        <div class="content has-text-justified">
          <p>
            On Livesum, which requires numerical reasoning and aggregation from Chinese social media posts, Map&Make achieves lower error rates and RMSE across different event categories. The pipeline's atomization step helps identify individual numerical facts before aggregation, reducing both undercounting and overcounting errors.
          </p>
        </div>
        <img src="./static/images/table4.png" width="600"/>
        <br><br>

        <!-- Wiki40B -->
        <h2 class="title is-3">Wiki40B: Open-Domain Extraction</h2>
        <div class="content has-text-justified">
          <p>
            Wiki40B tests open-domain table extraction from diverse Wikipedia articles without predefined schemas. Map&Make's schema extraction step enables flexible adaptation to varied content types, demonstrating the pipeline's generalizability beyond sports and numerical aggregation tasks to arbitrary structured information extraction.
          </p>
        </div>
        <img src="./static/images/wiki40B-results.png" width="600"/>
      </div>
    </div>
  </div>
</section>


<!-- Analysis Section -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h1 class="title is-2">Analysis</h1>
        
        <h2 class="title is-3">Error Patterns</h2>
        <div class="content has-text-justified">
          <p>
            Analyzing error patterns on RotoWire reveals that Map&Make reduces both row and column errors compared to baselines, demonstrating improved schema coverage and entity recognition. The modular approach helps maintain consistency across table dimensions.
          </p>
        </div>
        <img src="./static/images/table5.png" width="400"/>
        <br><br>

        <h2 class="title is-3">Numerical Reasoning</h2>
        <div class="content has-text-justified">
          <p>
            On Livesum, we analyze overcounting (values exceeding ground truth) vs. undercounting (values below ground truth). Map&Make shows balanced RMSE across both error types, indicating more reliable numerical aggregation through its atomization-based approach.
          </p>
        </div>
        <img src="./static/images/rmse_comparison.png" width="500"/>
        <br><br>

        <h2 class="title is-3">Schema Coverage Scaling</h2>
        <div class="content has-text-justified">
          <p>
            As table sizes increase on RotoWire, Map&Make maintains higher schema coverage compared to baselines. The explicit schema extraction step enables the model to identify and populate more diverse column types, especially for complex multi-table scenarios.
          </p>
        </div>
        <img src="./static/images/trend.png" width="500"/>
      </div>
    </div>
  </div>
</section>

<!-- Fine-Tuning Section -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h1 class="title is-2">Fine-Tuning Smaller Models</h1>
        <div class="content has-text-justified">
          <p>
            Beyond inference-time prompting, Map&Make serves as a scalable data generation engine. We used Gemini 2.0 with our pipeline to generate high-quality supervision on the RotoWire training set, then fine-tuned LLaMA 3 8B Instruct. Results show that fine-tuning with Map&Make-generated data yields clear gains over Chain-of-Thought prompting in AutoQA (48.65 vs. 41.42) and player-level recall (61.58 vs. 57.74).
          </p>
          <br>
          <p>
            However, team-level recall drops (41.61 vs. 56.26), indicating challenges in aggregating broader content—likely due to formatting consistency and long-context reasoning limitations in smaller models. While the full Map&Make pipeline (inference-time) still outperforms both alternatives, these results demonstrate the framework's effectiveness as a data generation tool for low-resource and multilingual settings where fine-tuning is necessary.
          </p>
        </div>
        <br>
        <img src="./static/images/fine-tuning.png" width="600"/>
      </div>
    </div>
  </div>
</section>

<section class="footer">
  <div class="container is-max-desktop">
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{ahuja-etal-2025-map,
    title = "Map{\&}Make: Schema Guided Text to Table Generation",
    author = "Ahuja, Naman  and
      Bardoliya, Fenil  and
      Baral, Chitta  and
      Gupta, Vivek",
    editor = "Che, Wanxiang  and
      Nabende, Joyce  and
      Shutova, Ekaterina  and
      Pilehvar, Mohammad Taher",
    booktitle = "Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2025",
    address = "Vienna, Austria",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.acl-long.1460/",
    pages = "30249--30262",
    ISBN = "979-8-89176-251-0",
    abstract = "Transforming dense, unstructured text into interpretable tables{---}commonly referred to as Text-to-Table generation{---}is a key task in information extraction. Existing methods often overlook what complex information to extract and how to infer it from text. We present Map{\&}Make, a versatile approach that decomposes text into atomic propositions to infer latent schemas, which are then used to generate tables capturing both qualitative nuances and quantitative facts. We evaluate our method on three challenging datasets: Rotowire, known for its complex, multi-table schema; Livesum which requires numerical aggregation; and Wiki40 which require open text extraction from mulitple domains. By correcting hallucination errors in Rotowire, we also provide a cleaner benchmark. Our method shows significant gains in both accuracy and interpretability across comprehensive comparative and referenceless metrics. Finally, ablation studies highlight the key factors driving performance and validate the utility of our approach in structured summarization. Code and data are available at: https://coral-lab-asu.github.io/map-make."
} 
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <!-- <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div> -->
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <!-- <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p> -->
          <p>
            This page was adopted from the <a
              href="https://nerfies.github.io">Nerfies</a> project page.
            This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
